# Task Brief — Capacity–volume correlation study (E4)

- **Status**: Draft
- **Last updated**: 2025-10-04
- **Owner / DRI**: Unassigned
- **Related docs**: `docs/tasks/02-task-portfolio.md`, `docs/algorithm-implementation-plan.md`

## 1. Context and intent
We want to analyse how symplectic capacities correlate with volumes and other geometric invariants across the curated dataset. This study tests conjectured relationships, searches for clustering behaviour, and may reveal candidate counterexamples or new hypotheses.

## 2. Objectives and non-goals

### In scope
- Compute relevant capacities and volumes using reference implementations from the restructured geometry modules.
- Perform statistical analyses (correlations, regressions, clustering) to identify trends.
- Visualise relationships via plots or interactive notebooks for rapid inspection.
- Document findings, including surprising outliers or subclasses warranting deeper theoretical work.

### Out of scope
- Exhaustive hyperparameter tuning of statistical models; keep analyses interpretable.
- Automating publication-quality plots; draft visuals suitable for internal reasoning first.
- Claiming proofs based on empirical trends.

## 3. Deliverables and exit criteria
- Analysis notebook(s) with reproducible code to compute metrics and generate plots.
- Summary report (captured in the task brief or weekly progress report) describing correlations, notable clusters, and recommended next steps.
- Exported figures or tables saved under `docs/figures/`, generated by scripts/notebooks
  committed elsewhere and copied in once vetted.

## 4. Dependencies and prerequisites
- Completion of E1 dataset; optional benefits from E2/E3 insights.
- Availability of benchmark harness to ensure computations stay within runtime budgets.
- Agreement on statistical tooling (e.g., pandas, seaborn, scikit-learn) already present in environment or added with justification.

## 5. Execution plan and checkpoints
1. **Metric selection**: list capacities/volumes to compare and confirm availability.
2. **Data ingestion**: load dataset, ensure schema compatibility, and compute derived metrics.
3. **Exploratory analysis**: run correlation matrices, scatter plots, and clustering heuristics.
4. **Deep dives**: investigate anomalies and document hypotheses.
5. **Reporting**: compile narrative and visuals, highlight follow-up questions.

## 6. Effort and resource estimates
- **Agent time**: Medium (≈ 0.5–1 agent-week)
- **Compute budget**: Low to Medium (depends on dataset size; primarily CPU)
- **Expert/PI involvement**: Medium (interpretation of statistical findings)

## 7. Testing, benchmarks, and verification
- Reuse dataset validation from E1.
- Add unit checks for derived metrics (e.g., verifying invariants hold for known shapes).
- Optional: incorporate lightweight regression tests ensuring notebooks execute via `pytest --nbmake` or similar.

## 8. Risks, mitigations, and escalation triggers
- **Risk**: Spurious correlations due to small dataset. **Mitigation**: report confidence intervals, avoid overclaiming.
- **Risk**: Visualization or statistical tooling not preinstalled. **Mitigation**: request dependency additions via maintainer if necessary.
- **Escalation triggers**: Need for additional data generation, statistical ambiguity requiring expert interpretation.

## 9. Follow-on work
- Inform E5 stress tests or new conjectures.
- Suggest theoretical investigations or dataset extensions targeting identified outliers.
